{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51txI3Y00dmM",
        "outputId": "8b865fe5-948c-4cf3-f45a-96f200e0f018"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU is available and being used.\n",
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "from torchvision.models import resnet18, ResNet18_Weights\n",
        "import random\n",
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision.transforms import Resize\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "import torch.quantization\n",
        "from torch.utils.data import random_split\n",
        "from torch.utils.data import DataLoader\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "\n",
        "# use GPU if available\n",
        "if torch.cuda.is_available():\n",
        "        device = torch.device(\"cuda\")\n",
        "        print(\"GPU is available and being used.\")\n",
        "else:\n",
        "        device = torch.device(\"cpu\")\n",
        "        print(\"GPU is not available, using CPU instead.\")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters:\n",
        "learning_rate = 0.0005\n",
        "momentum = 0.9\n",
        "weight_decay = 1e-3\n",
        "\n",
        "num_epochs = 61\n",
        "T_max = num_epochs\n",
        "eta_min = 1e-5\n"
      ],
      "metadata": {
        "id": "zaVFAHAq3fS_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Basic block and RestNet18 architecture"
      ],
      "metadata": {
        "id": "Ug7Kcivp_2tS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1  # No expansion in BasicBlock\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1, downsample=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.stride = stride\n",
        "\n",
        "        # First convolutional layer\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_channels, out_channels,\n",
        "            kernel_size=kernel_size, stride=stride, padding=padding, bias=False\n",
        "        )\n",
        "\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        # Second convolutional layer\n",
        "        self.conv2 = nn.Conv2d(\n",
        "            out_channels, out_channels,\n",
        "            kernel_size=kernel_size, stride=1, padding=padding, bias=False\n",
        "        )\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        # Downsample layer for shortcut connection (if needed)\n",
        "        self.downsample = downsample\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x  # Save the input tensor for the shortcut\n",
        "\n",
        "        # First layer\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        # Second layer\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        # Apply downsampling to the identity if necessary\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        # Add the identity (shortcut connection)\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "N9XtbMR00io-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet18(nn.Module):\n",
        "    def __init__(self, num_classes=1000):\n",
        "        super(ResNet18, self).__init__()\n",
        "\n",
        "        # Initial Convolution and Max Pool\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_channels=3, out_channels=64,\n",
        "            kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "        # Define layers using your BasicBlock\n",
        "        self.layer1 = self._make_layer(64, 64, 2, stride=1)\n",
        "        self.layer2 = self._make_layer(64, 128, 2, stride=2)\n",
        "        self.layer3 = self._make_layer(128, 256, 2, stride=2)\n",
        "        self.layer4 = self._make_layer(256, 512, 2, stride=2)\n",
        "\n",
        "\n",
        "        # Adaptive Average Pooling\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "\n",
        "        # Fully connected layer\n",
        "        self.fc = nn.Linear(512 * BasicBlock.expansion, num_classes)\n",
        "\n",
        "        # Initialize weights\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def _make_layer(self, in_channels, out_channels, blocks, stride):\n",
        "        downsample = None\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(BasicBlock(in_channels, out_channels, stride=stride, downsample=downsample))\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(BasicBlock(out_channels, out_channels))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)"
      ],
      "metadata": {
        "id": "MLr8Iy-w0kRn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Retrain from pretrain model if needed"
      ],
      "metadata": {
        "id": "p3T4Zabq_Jpp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = ResNet18(num_classes=100)  # Adjusted to CIFAR-100 classes\n",
        "\n",
        "# Load pretrained weights\n",
        "pretrained_dict = models.resnet18(pretrained=True).state_dict()\n",
        "model_dict = model.state_dict()\n",
        "\n",
        "# Filter out unnecessary keys, particularly focusing on the fully connected layer\n",
        "pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict and model_dict[k].size() == v.size()}\n",
        "\n",
        "# Overwrite entries in the existing state dict\n",
        "model_dict.update(pretrained_dict)\n",
        "\n",
        "# Load the new state dict\n",
        "model.load_state_dict(model_dict)\n",
        "\n",
        "# Freeze all layers first\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Unfreeze the deeper layers and fully connected layer for fine-tuning\n",
        "for param in model.layer4.parameters():\n",
        "    param.requires_grad = True\n",
        "for param in model.fc.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# Verify which layers are frozen and which are not (optional, for verification)\n",
        "for name, param in model.named_parameters():\n",
        "    print(f\"{name} is {'unfrozen' if param.requires_grad else 'frozen'}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWTUEuOs0mEi",
        "outputId": "56ce8532-3d20-469c-c026-bfafc89edd85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 176MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "conv1.weight is frozen\n",
            "bn1.weight is frozen\n",
            "bn1.bias is frozen\n",
            "layer1.0.conv1.weight is frozen\n",
            "layer1.0.bn1.weight is frozen\n",
            "layer1.0.bn1.bias is frozen\n",
            "layer1.0.conv2.weight is frozen\n",
            "layer1.0.bn2.weight is frozen\n",
            "layer1.0.bn2.bias is frozen\n",
            "layer1.1.conv1.weight is frozen\n",
            "layer1.1.bn1.weight is frozen\n",
            "layer1.1.bn1.bias is frozen\n",
            "layer1.1.conv2.weight is frozen\n",
            "layer1.1.bn2.weight is frozen\n",
            "layer1.1.bn2.bias is frozen\n",
            "layer2.0.conv1.weight is frozen\n",
            "layer2.0.bn1.weight is frozen\n",
            "layer2.0.bn1.bias is frozen\n",
            "layer2.0.conv2.weight is frozen\n",
            "layer2.0.bn2.weight is frozen\n",
            "layer2.0.bn2.bias is frozen\n",
            "layer2.0.downsample.0.weight is frozen\n",
            "layer2.0.downsample.1.weight is frozen\n",
            "layer2.0.downsample.1.bias is frozen\n",
            "layer2.1.conv1.weight is frozen\n",
            "layer2.1.bn1.weight is frozen\n",
            "layer2.1.bn1.bias is frozen\n",
            "layer2.1.conv2.weight is frozen\n",
            "layer2.1.bn2.weight is frozen\n",
            "layer2.1.bn2.bias is frozen\n",
            "layer3.0.conv1.weight is frozen\n",
            "layer3.0.bn1.weight is frozen\n",
            "layer3.0.bn1.bias is frozen\n",
            "layer3.0.conv2.weight is frozen\n",
            "layer3.0.bn2.weight is frozen\n",
            "layer3.0.bn2.bias is frozen\n",
            "layer3.0.downsample.0.weight is frozen\n",
            "layer3.0.downsample.1.weight is frozen\n",
            "layer3.0.downsample.1.bias is frozen\n",
            "layer3.1.conv1.weight is frozen\n",
            "layer3.1.bn1.weight is frozen\n",
            "layer3.1.bn1.bias is frozen\n",
            "layer3.1.conv2.weight is frozen\n",
            "layer3.1.bn2.weight is frozen\n",
            "layer3.1.bn2.bias is frozen\n",
            "layer4.0.conv1.weight is unfrozen\n",
            "layer4.0.bn1.weight is unfrozen\n",
            "layer4.0.bn1.bias is unfrozen\n",
            "layer4.0.conv2.weight is unfrozen\n",
            "layer4.0.bn2.weight is unfrozen\n",
            "layer4.0.bn2.bias is unfrozen\n",
            "layer4.0.downsample.0.weight is unfrozen\n",
            "layer4.0.downsample.1.weight is unfrozen\n",
            "layer4.0.downsample.1.bias is unfrozen\n",
            "layer4.1.conv1.weight is unfrozen\n",
            "layer4.1.bn1.weight is unfrozen\n",
            "layer4.1.bn1.bias is unfrozen\n",
            "layer4.1.conv2.weight is unfrozen\n",
            "layer4.1.bn2.weight is unfrozen\n",
            "layer4.1.bn2.bias is unfrozen\n",
            "fc.weight is unfrozen\n",
            "fc.bias is unfrozen\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Retrain if needed\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "start_epoch = 0\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=T_max, eta_min=eta_min)\n",
        "\n",
        "# Verify the model\n",
        "print(\"start epoch: \", start_epoch)\n",
        "for name, param in model.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        print(name, param.data.shape, param.data.sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPbmmEUC3kMb",
        "outputId": "bd03e0cd-3871-404f-c2c8-5f0ac1fb462b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "start epoch:  0\n",
            "layer4.0.conv1.weight torch.Size([512, 256, 3, 3]) tensor(-1845.7561, device='cuda:0')\n",
            "layer4.0.bn1.weight torch.Size([512]) tensor(135.3306, device='cuda:0')\n",
            "layer4.0.bn1.bias torch.Size([512]) tensor(-115.5699, device='cuda:0')\n",
            "layer4.0.conv2.weight torch.Size([512, 512, 3, 3]) tensor(-3073.9663, device='cuda:0')\n",
            "layer4.0.bn2.weight torch.Size([512]) tensor(217.2513, device='cuda:0')\n",
            "layer4.0.bn2.bias torch.Size([512]) tensor(-101.1886, device='cuda:0')\n",
            "layer4.0.downsample.0.weight torch.Size([512, 256, 1, 1]) tensor(-110.5000, device='cuda:0')\n",
            "layer4.0.downsample.1.weight torch.Size([512]) tensor(128.3286, device='cuda:0')\n",
            "layer4.0.downsample.1.bias torch.Size([512]) tensor(-101.1886, device='cuda:0')\n",
            "layer4.1.conv1.weight torch.Size([512, 512, 3, 3]) tensor(-5334.5947, device='cuda:0')\n",
            "layer4.1.bn1.weight torch.Size([512]) tensor(147.7632, device='cuda:0')\n",
            "layer4.1.bn1.bias torch.Size([512]) tensor(-123.7711, device='cuda:0')\n",
            "layer4.1.conv2.weight torch.Size([512, 512, 3, 3]) tensor(-254.1285, device='cuda:0')\n",
            "layer4.1.bn2.weight torch.Size([512]) tensor(949.1506, device='cuda:0')\n",
            "layer4.1.bn2.bias torch.Size([512]) tensor(140.1969, device='cuda:0')\n",
            "fc.weight torch.Size([100, 512]) tensor(-0.2422, device='cuda:0')\n",
            "fc.bias torch.Size([100]) tensor(-0.2407, device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train"
      ],
      "metadata": {
        "id": "fwoArtc1_ZkR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define transformations for CIFAR-100 dataset\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Download the CIFAR-100 training dataset\n",
        "download_train_dataset = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform=transform_train)\n",
        "download_test_dataset = torchvision.datasets.CIFAR100(root='./data', train=False, download=True, transform=transform_test)\n",
        "\n",
        "batch_size = 64\n",
        "# Create DataLoader for training and validation datasets\n",
        "train_loader = DataLoader(download_train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(download_test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5-WOEF03PB_",
        "outputId": "dc7d5ae3-e12e-45e4-c0e8-4a5d391f9960"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./data/cifar-100-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 169M/169M [00:18<00:00, 9.00MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-100-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3qpsj2M3YuS",
        "outputId": "7ec9699d-91fc-47ad-c110-998478ebebb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_checkpoint(model, optimizer, path):\n",
        "    checkpoint = torch.load(path, map_location=device)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    epoch = checkpoint['epoch']\n",
        "    model.to(device)\n",
        "\n",
        "    for state in optimizer.state.values():\n",
        "        for k, v in state.items():\n",
        "            if isinstance(v, torch.Tensor):\n",
        "                state[k] = v.to(device)\n",
        "    return model, optimizer, epoch\n",
        "\n",
        "\n",
        "\n",
        "# Example usage before resuming training\n",
        "checkpoint_path = '/content/drive/My Drive/Colab Notebooks/checkpoints/transfer_learning_checkpoint.pth'\n",
        "model = ResNet18(num_classes=100)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "\n",
        "model, optimizer, start_epoch = load_checkpoint(model, optimizer, checkpoint_path)\n",
        "model.to(device)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Create model, schedueler\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=T_max, eta_min=eta_min)\n",
        "\n",
        "# Freeze all layers first\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Unfreeze the deeper layers and fully connected layer for fine-tuning\n",
        "for param in model.layer3.parameters():\n",
        "    param.requires_grad = True\n",
        "for param in model.layer4.parameters():\n",
        "    param.requires_grad = True\n",
        "for param in model.fc.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# Verify the model\n",
        "print(\"start epoch: \", start_epoch)\n",
        "for name, param in model.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        print(name, param.data.shape, param.data.sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSZrWiw-98aX",
        "outputId": "b55ba927-b93b-4121-c282-b2e91f08e4db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-649cf205bd2c>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(path, map_location=device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "start epoch:  54\n",
            "layer3.0.conv1.weight torch.Size([256, 128, 3, 3]) tensor(-221.4406, device='cuda:0')\n",
            "layer3.0.bn1.weight torch.Size([256]) tensor(69.2772, device='cuda:0')\n",
            "layer3.0.bn1.bias torch.Size([256]) tensor(-27.6587, device='cuda:0')\n",
            "layer3.0.conv2.weight torch.Size([256, 256, 3, 3]) tensor(-243.0699, device='cuda:0')\n",
            "layer3.0.bn2.weight torch.Size([256]) tensor(72.6982, device='cuda:0')\n",
            "layer3.0.bn2.bias torch.Size([256]) tensor(-8.6190, device='cuda:0')\n",
            "layer3.0.downsample.0.weight torch.Size([256, 128, 1, 1]) tensor(-22.2722, device='cuda:0')\n",
            "layer3.0.downsample.1.weight torch.Size([256]) tensor(18.9305, device='cuda:0')\n",
            "layer3.0.downsample.1.bias torch.Size([256]) tensor(-8.6190, device='cuda:0')\n",
            "layer3.1.conv1.weight torch.Size([256, 256, 3, 3]) tensor(-513.3556, device='cuda:0')\n",
            "layer3.1.bn1.weight torch.Size([256]) tensor(61.9338, device='cuda:0')\n",
            "layer3.1.bn1.bias torch.Size([256]) tensor(-55.8490, device='cuda:0')\n",
            "layer3.1.conv2.weight torch.Size([256, 256, 3, 3]) tensor(-500.1842, device='cuda:0')\n",
            "layer3.1.bn2.weight torch.Size([256]) tensor(52.6131, device='cuda:0')\n",
            "layer3.1.bn2.bias torch.Size([256]) tensor(-36.0350, device='cuda:0')\n",
            "layer4.0.conv1.weight torch.Size([512, 256, 3, 3]) tensor(-269.2462, device='cuda:0')\n",
            "layer4.0.bn1.weight torch.Size([512]) tensor(37.9735, device='cuda:0')\n",
            "layer4.0.bn1.bias torch.Size([512]) tensor(-46.8112, device='cuda:0')\n",
            "layer4.0.conv2.weight torch.Size([512, 512, 3, 3]) tensor(-444.0891, device='cuda:0')\n",
            "layer4.0.bn2.weight torch.Size([512]) tensor(51.9270, device='cuda:0')\n",
            "layer4.0.bn2.bias torch.Size([512]) tensor(-43.4808, device='cuda:0')\n",
            "layer4.0.downsample.0.weight torch.Size([512, 256, 1, 1]) tensor(-59.2816, device='cuda:0')\n",
            "layer4.0.downsample.1.weight torch.Size([512]) tensor(39.0488, device='cuda:0')\n",
            "layer4.0.downsample.1.bias torch.Size([512]) tensor(-43.4808, device='cuda:0')\n",
            "layer4.1.conv1.weight torch.Size([512, 512, 3, 3]) tensor(-1055.5193, device='cuda:0')\n",
            "layer4.1.bn1.weight torch.Size([512]) tensor(32.6230, device='cuda:0')\n",
            "layer4.1.bn1.bias torch.Size([512]) tensor(-33.8524, device='cuda:0')\n",
            "layer4.1.conv2.weight torch.Size([512, 512, 3, 3]) tensor(-26.4979, device='cuda:0')\n",
            "layer4.1.bn2.weight torch.Size([512]) tensor(330.8979, device='cuda:0')\n",
            "layer4.1.bn2.bias torch.Size([512]) tensor(123.6235, device='cuda:0')\n",
            "fc.weight torch.Size([100, 512]) tensor(-47.8249, device='cuda:0')\n",
            "fc.bias torch.Size([100]) tensor(0.0065, device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def save_checkpoint(model, optimizer, epoch, path):\n",
        "    # Create the directory if it doesn't exist\n",
        "    import os\n",
        "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
        "    torch.save({\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "    }, path)"
      ],
      "metadata": {
        "id": "RSJITlsE5JRR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, data_loader, device):\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient calculation during evaluation\n",
        "        for images, labels in data_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(images)  # Get predictions\n",
        "            _, predicted = torch.max(outputs.data, 1)  # Get predicted class labels\n",
        "\n",
        "            total += labels.size(0)  # Update total number of samples\n",
        "            correct += (predicted == labels).sum().item()  # Update number of correct predictions\n",
        "\n",
        "    accuracy = 100 * correct / total  # Calculate accuracy\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "pTuKlF135EV1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializing parameters with zeroes\n",
        "total_train = torch.zeros(num_epochs)\n",
        "correct_train = torch.zeros(num_epochs)\n",
        "avg_loss_train = torch.zeros(num_epochs)\n",
        "accuracy_train = torch.zeros(num_epochs)\n",
        "\n",
        "# TRAINING LOOP\n",
        "print(\"START TRAINING........\")\n",
        "train_losses = [] # store training loss for each batch\n",
        "train_accuracies = [] # store training accuracy for each batch\n",
        "test_accuracies = [] #store test accuracy after each epoch\n",
        "\n",
        "for epoch in range(start_epoch, num_epochs):\n",
        "  model.train() # Set the model to training mode\n",
        "  batch_losses = []\n",
        "  batch_accuracies = []\n",
        "\n",
        "  for input, target in train_loader:\n",
        "      input, target = input.to(device), target.to(device)\n",
        "\n",
        "      # forward\n",
        "      output = model(input)\n",
        "      loss = criterion(output, target)\n",
        "\n",
        "      # backward\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      # *** Add gradient clipping here ***\n",
        "      torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
        "\n",
        "\n",
        "      # save data\n",
        "      batch_losses.append(loss.item())\n",
        "      _, predicted = output.max(1)\n",
        "      total = target.size(0)\n",
        "      correct = predicted.eq(target).sum().item()\n",
        "      batch_accuracies.append(100. * correct / total)\n",
        "\n",
        "  train_losses.append(batch_losses) # append the batch losses for this epoch to the main list\n",
        "  train_accuracies.append(batch_accuracies) # append the batch accuracies for this epoch to the main list\n",
        "  avg_loss_train[epoch] = np.mean(batch_losses) # calculate and store average loss for the epoch\n",
        "  accuracy_train[epoch] = np.mean(batch_accuracies) # calculate and store average accuracy for the epoch\n",
        "\n",
        "  #Validation after each epoch\n",
        "  test_accuracy = evaluate(model, test_loader, device)\n",
        "  test_accuracies.append(test_accuracy)\n",
        "\n",
        "  checkpoint_path = '/content/drive/My Drive/Colab Notebooks/checkpoints/transfer_learning_checkpoint.pth'\n",
        "  if (epoch + 1) % 2 == 1:\n",
        "        save_checkpoint(model, optimizer, epoch, checkpoint_path)\n",
        "  print(f\"Epoch [{epoch+1}/{num_epochs}] - \"\n",
        "        f\"Train Loss: {avg_loss_train[epoch]:.4f} - \"\n",
        "        f\"Train Accuracy: {accuracy_train[epoch]:.2f}% - \"\n",
        "        f\"Validation Accuracy: {test_accuracy:.2f}% \"\n",
        "        )\n",
        "\n",
        "  scheduler.step()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xG_Ovd85LhH",
        "outputId": "6f802138-8567-41f1-edb6-6b427547bb67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "START TRAINING........\n",
            "Epoch [55/61] - Train Loss: 0.2630 - Train Accuracy: 93.06% - Validation Accuracy: 74.24% \n",
            "Epoch [56/61] - Train Loss: 0.2616 - Train Accuracy: 93.08% - Validation Accuracy: 74.06% \n",
            "Epoch [57/61] - Train Loss: 0.2516 - Train Accuracy: 93.44% - Validation Accuracy: 74.42% \n",
            "Epoch [58/61] - Train Loss: 0.2499 - Train Accuracy: 93.54% - Validation Accuracy: 74.68% \n",
            "Epoch [59/61] - Train Loss: 0.2421 - Train Accuracy: 93.78% - Validation Accuracy: 74.78% \n",
            "Epoch [60/61] - Train Loss: 0.2308 - Train Accuracy: 94.10% - Validation Accuracy: 74.28% \n",
            "Epoch [61/61] - Train Loss: 0.2338 - Train Accuracy: 93.97% - Validation Accuracy: 74.28% \n"
          ]
        }
      ]
    }
  ]
}