{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNq6HE3dXZZXn4thnyGf/4H"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Setup"],"metadata":{"id":"1Daysk-C_NbB"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","from torchvision.models import resnet18, ResNet18_Weights\n","import random\n","import copy\n","import matplotlib.pyplot as plt\n","import torch.nn as nn\n","import numpy as np\n","import torch\n","import torch.optim as optim\n","import torchvision\n","from torchvision.transforms import Resize\n","import torchvision.transforms as transforms\n","import torchvision.models as models\n","import torch.quantization\n","import torch.nn.functional as F\n","from torch.utils.data import random_split\n","from torch.utils.data import DataLoader\n","import pandas as pd\n","import time\n","\n","# use GPU if available\n","if torch.cuda.is_available():\n","        device = torch.device(\"cuda\")\n","        print(\"GPU is available and being used.\")\n","else:\n","        device = torch.device(\"cpu\")\n","        print(\"GPU is not available, using CPU instead.\")\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using device: {device}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ybHCPnxk_RK5","executionInfo":{"status":"ok","timestamp":1734573303611,"user_tz":-480,"elapsed":33727,"user":{"displayName":"Hung-Ting Tsai","userId":"08907122957587206864"}},"outputId":"373375ec-8c94-4cd3-e11d-006b0544c653"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","GPU is not available, using CPU instead.\n","Using device: cpu\n"]}]},{"cell_type":"markdown","source":["# ResNet18"],"metadata":{"id":"vTJyc_IB-OYg"}},{"cell_type":"code","source":["class BasicBlock(nn.Module):\n","    expansion = 1  # No expansion in BasicBlock\n","\n","    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1, downsample=None):\n","        super(BasicBlock, self).__init__()\n","        self.stride = stride\n","\n","        # First convolutional layer\n","        self.conv1 = nn.Conv2d(\n","            in_channels, out_channels,\n","            kernel_size=kernel_size, stride=stride, padding=padding, bias=False\n","        )\n","\n","        self.bn1 = nn.BatchNorm2d(out_channels)\n","        self.relu = nn.ReLU(inplace=True)\n","\n","        # Second convolutional layer\n","        self.conv2 = nn.Conv2d(\n","            out_channels, out_channels,\n","            kernel_size=kernel_size, stride=1, padding=padding, bias=False\n","        )\n","        self.bn2 = nn.BatchNorm2d(out_channels)\n","\n","        # Downsample layer for shortcut connection (if needed)\n","        self.downsample = downsample\n","\n","    def forward(self, x):\n","        identity = x  # Save the input tensor for the shortcut\n","\n","        # First layer\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","\n","        # Second layer\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","\n","        # Apply downsampling to the identity if necessary\n","        if self.downsample is not None:\n","            identity = self.downsample(x)\n","\n","        # Add the identity (shortcut connection)\n","        out += identity\n","        out = self.relu(out)\n","\n","        return out"],"metadata":{"id":"oGCjyexhqhZK","executionInfo":{"status":"ok","timestamp":1734573308161,"user_tz":-480,"elapsed":843,"user":{"displayName":"Hung-Ting Tsai","userId":"08907122957587206864"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["class ResNet18(nn.Module):\n","    def __init__(self, num_classes=1000):\n","        super(ResNet18, self).__init__()\n","\n","        # Initial Convolution and Max Pool\n","        self.conv1 = nn.Conv2d(\n","            in_channels=3, out_channels=64,\n","            kernel_size=7, stride=2, padding=3, bias=False)\n","        self.bn1 = nn.BatchNorm2d(64)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n","\n","        # Define layers using your BasicBlock\n","        self.layer1 = self._make_layer(64, 64, 2, stride=1)\n","        self.layer2 = self._make_layer(64, 128, 2, stride=2)\n","        self.layer3 = self._make_layer(128, 256, 2, stride=2)\n","        self.layer4 = self._make_layer(256, 512, 2, stride=2)\n","\n","\n","        # Adaptive Average Pooling\n","        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n","\n","        # Fully connected layer\n","        self.fc = nn.Linear(512 * BasicBlock.expansion, num_classes)\n","\n","        # Initialize weights\n","        self._initialize_weights()\n","\n","    def _make_layer(self, in_channels, out_channels, blocks, stride):\n","        downsample = None\n","        if stride != 1 or in_channels != out_channels:\n","            downsample = nn.Sequential(\n","                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(out_channels)\n","            )\n","\n","        layers = []\n","        layers.append(BasicBlock(in_channels, out_channels, stride=stride, downsample=downsample))\n","        for _ in range(1, blocks):\n","            layers.append(BasicBlock(out_channels, out_channels))\n","\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = self.relu(x)\n","        x = self.maxpool(x)\n","\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","        x = self.layer4(x)\n","\n","        x = self.avgpool(x)\n","        x = torch.flatten(x, 1)\n","        x = self.fc(x)\n","\n","        return x\n","\n","    def _initialize_weights(self):\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n","            elif isinstance(m, nn.BatchNorm2d):\n","                nn.init.constant_(m.weight, 1)\n","                nn.init.constant_(m.bias, 0)"],"metadata":{"id":"Lzxx8P51qUoX","executionInfo":{"status":"ok","timestamp":1734573309001,"user_tz":-480,"elapsed":2,"user":{"displayName":"Hung-Ting Tsai","userId":"08907122957587206864"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["def fixed_point_quantize_weights(weights, total_bits, int_bits):\n","    frac_bits = total_bits - int_bits\n","    delta = 2 ** (-frac_bits)\n","    max_val = (2 ** (total_bits - 1) - 1) * delta\n","    min_val = -2 ** (total_bits - 1) * delta\n","\n","    q_weights = torch.clamp(torch.round(weights / delta), min_val / delta, max_val / delta) * delta\n","    return q_weights"],"metadata":{"id":"BUdFcV6WR-GM","executionInfo":{"status":"ok","timestamp":1734573309001,"user_tz":-480,"elapsed":2,"user":{"displayName":"Hung-Ting Tsai","userId":"08907122957587206864"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["class QuantizedConv2d(nn.Conv2d):\n","    def __init__(self, *args, total_bits=8, weight_int_bits=2, input_int_bits=2, output_int_bits=2, **kwargs):\n","        super(QuantizedConv2d, self).__init__(*args, **kwargs)\n","        self.total_bits = total_bits\n","        self.weight_int_bits = weight_int_bits\n","        self.input_int_bits = input_int_bits\n","        self.output_int_bits = output_int_bits\n","    def forward(self, input):\n","        # quantize input\n","        quantized_input = fixed_point_quantize_weights(input, self.total_bits, self.input_int_bits)\n","        # quantize weights\n","        original_weights = self.weight.data\n","        quantized_weights = fixed_point_quantize_weights(original_weights, self.total_bits, self.weight_int_bits)\n","        output = F.conv2d(quantized_input, quantized_weights, self.bias, self.stride,\n","                          self.padding, self.dilation, self.groups)\n","        # quantize output\n","        quantized_output = fixed_point_quantize_weights(output, self.total_bits, self.output_int_bits)\n","        return quantized_output"],"metadata":{"id":"Mis65zuZSgWD","executionInfo":{"status":"ok","timestamp":1734573309001,"user_tz":-480,"elapsed":1,"user":{"displayName":"Hung-Ting Tsai","userId":"08907122957587206864"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["## quantize conv\n","def quantize_conv2d(model, total_bits, weight_int_bits, input_int_bits, output_int_bits):\n","    for name, m in model.named_children():\n","        if isinstance(m, nn.Conv2d):\n","            new_layer = QuantizedConv2d(\n","                in_channels=m.in_channels,\n","                out_channels=m.out_channels,\n","                kernel_size=m.kernel_size,\n","                stride=m.stride,\n","                padding=m.padding,\n","                dilation=m.dilation,\n","                groups=m.groups,\n","                bias=(m.bias is not None),\n","                total_bits=total_bits,\n","                weight_int_bits=weight_int_bits,\n","                input_int_bits=input_int_bits,\n","                output_int_bits=output_int_bits\n","            )\n","            new_layer.weight.data = fixed_point_quantize_weights(m.weight.data.clone(), total_bits, weight_int_bits)\n","            if m.bias is not None:\n","                new_layer.bias.data = fixed_point_quantize_weights(m.bias.data.clone(), total_bits, weight_int_bits)\n","\n","            setattr(model, name, new_layer)\n","        elif len(list(m.children())) > 0:\n","            quantize_conv2d(m, total_bits, weight_int_bits, input_int_bits, output_int_bits)"],"metadata":{"id":"8fd1vqhQTWll","executionInfo":{"status":"ok","timestamp":1734573309001,"user_tz":-480,"elapsed":1,"user":{"displayName":"Hung-Ting Tsai","userId":"08907122957587206864"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["model = ResNet18(num_classes=100)\n","quantized_model = copy.deepcopy(model)\n","\n","weight_int_bits = 2\n","input_int_bits = 3\n","output_int_bits = 3\n","\n","quantize_conv2d(quantized_model, 8, weight_int_bits, input_int_bits, output_int_bits)\n","quantized_model = quantized_model.to(device)"],"metadata":{"id":"bBdcdzI3SjFm","executionInfo":{"status":"ok","timestamp":1734573309663,"user_tz":-480,"elapsed":663,"user":{"displayName":"Hung-Ting Tsai","userId":"08907122957587206864"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["# Save Weights"],"metadata":{"id":"slBn8j61_E8X"}},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P6EvpnTa9UOW","executionInfo":{"status":"ok","timestamp":1734573421784,"user_tz":-480,"elapsed":19401,"user":{"displayName":"Hung-Ting Tsai","userId":"08907122957587206864"}},"outputId":"e1ec29ac-a478-4348-cdd0-b6acc5b242f7"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-8-70fdc1e29a39>:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  checkpoint = torch.load(checkpoint_path, map_location=torch.device('cpu'))\n"]}],"source":["# Function to save tensor to binary file\n","def save_tensor_to_bin(tensor, filename):\n","    # Ensure the tensor is on CPU and convert to numpy array\n","    np_array = tensor.cpu().numpy()\n","    # Flatten the array to store it as a one-dimensional binary\n","    np_array.tofile(filename)\n","\n","# Load the model\n","checkpoint_path = '/content/drive/My Drive/Colab Notebooks/checkpoints/quantized_checkpoint.pth'\n","checkpoint = torch.load(checkpoint_path, map_location=torch.device('cpu'))\n","\n","# Load model state dict\n","model = quantized_model\n","model.load_state_dict(checkpoint['model_state_dict'])\n","\n","# Iterate through the model's layers and save weights to .bin files\n","save_dir = '/content/drive/My Drive/Colab Notebooks/bin_files/'\n","for name, param in model.named_parameters():\n","    if 'weight' in name:  # Check if the parameter is a weight matrix\n","        # Construct the full file path\n","        filename = f\"{save_dir}{name.replace('.', '_')}.bin\"\n","        save_tensor_to_bin(param.data, filename)"]},{"cell_type":"code","source":["def save_bn_params_to_bin(bn_layer, filename, eps=1e-5):\n","    \"\"\"\n","    Combines running_var and gamma into mult_factor and saves BN params.\n","\n","    Args:\n","        bn_layer: The Batch Normalization layer.\n","        filename: The path to save the binary file.\n","        eps: A small value added to running_var for numerical stability.\n","    \"\"\"\n","    # Calculate mult_factor\n","    mult_factor = bn_layer.weight / torch.sqrt(bn_layer.running_var + eps)\n","\n","    # Stack parameters in the desired order\n","    params = torch.stack([\n","        bn_layer.running_mean,\n","        mult_factor,\n","        bn_layer.bias\n","    ])\n","\n","    # Save to binary file\n","    np_array = params.cpu().detach().numpy()\n","    np_array.tofile(filename)\n","\n","def save_all_bn_params(model, save_dir):\n","    \"\"\"\n","    Iterates through the model and saves parameters for all BN layers.\n","\n","    Args:\n","        model: The PyTorch model.\n","        save_dir: The directory to save the binary files.\n","    \"\"\"\n","    for name, module in model.named_modules():\n","        if isinstance(module, nn.BatchNorm2d):  # Check if the module is a BN layer\n","            filename = f\"{save_dir}{name.replace('.', '_')}_combined.bin\"\n","            save_bn_params_to_bin(module, filename)\n","\n","# Example usage:\n","save_dir = '/content/drive/My Drive/Colab Notebooks/bin_files/'\n","save_all_bn_params(model, save_dir)"],"metadata":{"id":"Y1o_sBi88E2l","executionInfo":{"status":"ok","timestamp":1734573427691,"user_tz":-480,"elapsed":5909,"user":{"displayName":"Hung-Ting Tsai","userId":"08907122957587206864"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["# Other Test"],"metadata":{"id":"VjuaXzwHR9Br"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","\n","# Create a batch of inputs (e.g., batch size 4, channels 3, height and width 5)\n","x = torch.randn(4, 3, 5, 5)\n","\n","# Initialize the BatchNorm layer\n","bn = nn.BatchNorm2d(3)\n","\n","# Apply PyTorch BatchNorm\n","bn_out = bn(x)\n","\n","# Calculate mean and variance manually\n","mean = x.mean([0, 2, 3], keepdim=True)\n","var = x.var([0, 2, 3], keepdim=True, unbiased=False)\n","epsilon = 1e-5\n","\n","# Normalize manually\n","y_norm = (x - mean) / torch.sqrt(var + epsilon)\n","\n","# Apply gamma and beta (initialized to 1 and 0 in BatchNorm)\n","gamma = bn.weight.view(1, 3, 1, 1)\n","beta = bn.bias.view(1, 3, 1, 1)\n","manual_out = y_norm * gamma + beta\n","\n","# Compare outputs\n","print(\"PyTorch BatchNorm Output:\", bn_out)\n","print(\"Manual Calculation Output:\", manual_out)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u5pV1ZuMR_Vn","executionInfo":{"status":"ok","timestamp":1734533972865,"user_tz":-480,"elapsed":418,"user":{"displayName":"Hung-Ting Tsai","userId":"08907122957587206864"}},"outputId":"4d4aca74-27c0-4a91-ced4-8914b7692baf"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["PyTorch BatchNorm Output: tensor([[[[-0.7487, -1.5081, -0.9805, -1.1135, -1.2354],\n","          [-0.4173,  0.8342, -0.4882, -1.5744,  1.1677],\n","          [ 0.3980, -0.7128,  2.4608,  1.0370, -0.4750],\n","          [ 0.3292, -2.1019, -0.1768, -0.1718, -0.5120],\n","          [-1.7837,  0.0476,  0.3870, -1.1638, -0.3408]],\n","\n","         [[ 0.7610,  0.9965,  0.7050,  0.9551,  1.3295],\n","          [-0.1368, -0.7595, -0.1605,  0.3042, -1.4841],\n","          [ 0.0178, -0.1560,  1.4304, -0.6366,  0.7241],\n","          [ 0.9487,  1.9683, -0.5929,  0.1596,  1.8587],\n","          [-1.6693,  1.7225,  0.6456,  1.1036, -0.3665]],\n","\n","         [[-0.5643, -1.3252,  1.4667,  0.4837,  0.6148],\n","          [-0.9203, -0.3524, -0.1319,  0.0644, -0.8730],\n","          [-2.1496,  0.9718, -0.3025, -1.0742, -0.5703],\n","          [ 1.5937, -1.4201,  0.8394,  1.0297, -0.4593],\n","          [-0.1068, -0.9915,  0.1236, -0.0887, -0.5852]]],\n","\n","\n","        [[[-0.1510, -1.0703, -0.2825,  0.5577, -0.1359],\n","          [-0.4731,  0.5029, -0.8611, -2.0631, -0.7074],\n","          [ 1.1328,  0.6303,  1.6363,  0.0935,  1.5661],\n","          [-1.1031, -0.9971,  0.7784, -0.3391,  1.8976],\n","          [ 0.6919,  0.8961,  1.0975, -1.2285,  0.4274]],\n","\n","         [[-0.7492, -0.0161,  0.5949, -0.7315,  0.2912],\n","          [ 0.7976,  0.3917, -0.3402,  0.5045, -1.5882],\n","          [-0.7579,  0.9737, -0.5295, -0.1749, -0.2553],\n","          [ 0.4125, -1.6824,  0.4801,  1.5705,  0.9391],\n","          [ 1.4519,  1.6567,  0.2661,  0.4718, -2.2204]],\n","\n","         [[-0.5781,  1.1831, -1.6982, -1.1885, -0.1520],\n","          [-0.4744,  1.1695, -0.5577,  0.5515, -0.3345],\n","          [ 0.3189,  1.0914,  0.9632, -1.1040,  0.6107],\n","          [-0.7099,  0.3742, -0.3483, -1.3377,  1.2522],\n","          [ 0.5228, -1.1099,  2.8601, -1.5896,  0.2792]]],\n","\n","\n","        [[[ 0.7319, -1.3121,  0.9641,  2.2570, -0.1222],\n","          [-0.1431,  0.0115,  0.9213,  0.7175,  0.3939],\n","          [ 0.5208,  1.7977,  0.5810,  0.1883,  0.3003],\n","          [ 0.3265, -1.2582,  0.1611,  2.1991, -0.6306],\n","          [-2.5629, -0.7352, -0.0784,  1.5824, -0.5321]],\n","\n","         [[ 0.1837,  0.8431, -1.0138,  1.9865, -0.3880],\n","          [-0.2028,  0.9997, -0.6795,  0.5769, -0.3116],\n","          [-0.4154,  0.3605, -0.8115, -1.2182,  0.5794],\n","          [-1.6943, -1.5097, -1.0054, -0.1687,  0.4888],\n","          [-0.8321, -0.3411, -1.4159, -0.5013,  1.0588]],\n","\n","         [[ 1.7461,  0.8240, -0.2984, -0.9401, -0.9683],\n","          [ 0.9753, -0.9055,  2.6481, -0.0274, -1.2228],\n","          [ 0.6058,  1.1951, -1.3629, -1.2157, -0.0481],\n","          [-1.3283,  1.2246, -0.1543, -0.2611, -0.2982],\n","          [ 2.0701,  0.7283,  0.5569, -0.4045, -0.1276]]],\n","\n","\n","        [[[ 1.2509, -1.7357, -0.5221,  0.1104, -0.8299],\n","          [-0.5864, -0.9325, -0.0129,  0.0471,  0.5901],\n","          [-0.7774,  0.5701, -0.5535,  0.7716,  0.3578],\n","          [ 0.1536, -0.9323,  0.7478,  1.0306, -0.5124],\n","          [-0.3872,  1.6442,  0.3576,  0.4391, -0.2217]],\n","\n","         [[-0.2781,  0.3027, -0.3314,  0.1545, -0.9797],\n","          [ 1.9451, -0.6262,  0.8849, -2.2760,  0.2491],\n","          [-0.0865, -0.8602, -1.3110, -1.4046, -1.1638],\n","          [-1.9655,  1.4516,  1.8328, -0.1248,  0.1271],\n","          [-0.3052, -0.9679, -0.1834,  0.4876, -0.5639]],\n","\n","         [[-1.0454,  0.6368,  0.4428, -0.2006,  0.0917],\n","          [ 0.1339,  0.0160,  1.2893, -1.7797, -1.2713],\n","          [ 1.0602, -0.0822,  0.8680,  1.4451,  0.1619],\n","          [-0.4764, -0.2096, -1.5318, -0.2305, -0.5706],\n","          [ 1.3856,  0.4619,  1.5183,  0.1662, -0.5573]]]],\n","       grad_fn=<NativeBatchNormBackward0>)\n","Manual Calculation Output: tensor([[[[-0.7487, -1.5081, -0.9805, -1.1135, -1.2354],\n","          [-0.4173,  0.8342, -0.4882, -1.5744,  1.1677],\n","          [ 0.3980, -0.7128,  2.4608,  1.0370, -0.4750],\n","          [ 0.3292, -2.1019, -0.1768, -0.1718, -0.5120],\n","          [-1.7837,  0.0476,  0.3870, -1.1638, -0.3408]],\n","\n","         [[ 0.7610,  0.9965,  0.7050,  0.9551,  1.3295],\n","          [-0.1368, -0.7595, -0.1605,  0.3042, -1.4841],\n","          [ 0.0178, -0.1560,  1.4304, -0.6366,  0.7241],\n","          [ 0.9487,  1.9683, -0.5929,  0.1596,  1.8587],\n","          [-1.6693,  1.7225,  0.6456,  1.1036, -0.3665]],\n","\n","         [[-0.5643, -1.3252,  1.4667,  0.4837,  0.6148],\n","          [-0.9203, -0.3524, -0.1319,  0.0644, -0.8730],\n","          [-2.1496,  0.9718, -0.3025, -1.0742, -0.5703],\n","          [ 1.5937, -1.4201,  0.8394,  1.0297, -0.4593],\n","          [-0.1068, -0.9915,  0.1236, -0.0887, -0.5852]]],\n","\n","\n","        [[[-0.1510, -1.0703, -0.2826,  0.5577, -0.1359],\n","          [-0.4731,  0.5029, -0.8611, -2.0631, -0.7074],\n","          [ 1.1328,  0.6303,  1.6363,  0.0935,  1.5661],\n","          [-1.1031, -0.9971,  0.7784, -0.3391,  1.8976],\n","          [ 0.6919,  0.8961,  1.0975, -1.2285,  0.4274]],\n","\n","         [[-0.7492, -0.0161,  0.5949, -0.7315,  0.2912],\n","          [ 0.7976,  0.3917, -0.3402,  0.5045, -1.5882],\n","          [-0.7579,  0.9737, -0.5295, -0.1749, -0.2553],\n","          [ 0.4125, -1.6824,  0.4801,  1.5705,  0.9391],\n","          [ 1.4519,  1.6567,  0.2661,  0.4718, -2.2204]],\n","\n","         [[-0.5781,  1.1831, -1.6982, -1.1885, -0.1520],\n","          [-0.4744,  1.1695, -0.5577,  0.5515, -0.3345],\n","          [ 0.3189,  1.0914,  0.9632, -1.1040,  0.6107],\n","          [-0.7099,  0.3742, -0.3483, -1.3377,  1.2522],\n","          [ 0.5228, -1.1099,  2.8601, -1.5896,  0.2792]]],\n","\n","\n","        [[[ 0.7319, -1.3121,  0.9641,  2.2570, -0.1222],\n","          [-0.1431,  0.0115,  0.9213,  0.7175,  0.3939],\n","          [ 0.5208,  1.7977,  0.5810,  0.1883,  0.3003],\n","          [ 0.3265, -1.2582,  0.1611,  2.1991, -0.6306],\n","          [-2.5629, -0.7352, -0.0784,  1.5824, -0.5321]],\n","\n","         [[ 0.1837,  0.8431, -1.0138,  1.9865, -0.3880],\n","          [-0.2028,  0.9997, -0.6795,  0.5769, -0.3116],\n","          [-0.4154,  0.3605, -0.8115, -1.2182,  0.5794],\n","          [-1.6943, -1.5097, -1.0054, -0.1687,  0.4888],\n","          [-0.8321, -0.3411, -1.4159, -0.5013,  1.0588]],\n","\n","         [[ 1.7461,  0.8240, -0.2984, -0.9401, -0.9683],\n","          [ 0.9753, -0.9055,  2.6481, -0.0274, -1.2228],\n","          [ 0.6058,  1.1951, -1.3629, -1.2157, -0.0481],\n","          [-1.3283,  1.2246, -0.1543, -0.2611, -0.2982],\n","          [ 2.0701,  0.7283,  0.5569, -0.4045, -0.1276]]],\n","\n","\n","        [[[ 1.2509, -1.7357, -0.5221,  0.1104, -0.8299],\n","          [-0.5864, -0.9325, -0.0129,  0.0471,  0.5901],\n","          [-0.7774,  0.5701, -0.5535,  0.7716,  0.3578],\n","          [ 0.1536, -0.9323,  0.7478,  1.0306, -0.5124],\n","          [-0.3872,  1.6442,  0.3576,  0.4391, -0.2217]],\n","\n","         [[-0.2781,  0.3027, -0.3314,  0.1545, -0.9797],\n","          [ 1.9451, -0.6262,  0.8849, -2.2760,  0.2491],\n","          [-0.0865, -0.8602, -1.3110, -1.4046, -1.1638],\n","          [-1.9655,  1.4516,  1.8328, -0.1248,  0.1271],\n","          [-0.3052, -0.9679, -0.1834,  0.4876, -0.5639]],\n","\n","         [[-1.0454,  0.6368,  0.4428, -0.2006,  0.0917],\n","          [ 0.1339,  0.0160,  1.2893, -1.7797, -1.2713],\n","          [ 1.0602, -0.0822,  0.8680,  1.4451,  0.1619],\n","          [-0.4764, -0.2096, -1.5318, -0.2305, -0.5706],\n","          [ 1.3856,  0.4619,  1.5183,  0.1662, -0.5573]]]],\n","       grad_fn=<AddBackward0>)\n"]}]},{"cell_type":"code","source":["# Define the size of the arrays\n","size = 24\n","\n","# Create sample arrays\n","array_1 = np.array([idx * 16 for idx in range(size)], dtype=np.int16)  # Sequential numbers scaled by 16\n","array_2 = np.array([(5 - idx) * 16 for idx in range(size)], dtype=np.int16)  # (5 - idx) scaled by 16\n","\n","# Save arrays to binary files\n","array_1.tofile(f\"{save_dir}array_1.bin\")\n","array_2.tofile(f\"{save_dir}array_2.bin\")"],"metadata":{"id":"6PqhExudpYhD","executionInfo":{"status":"ok","timestamp":1734540532631,"user_tz":-480,"elapsed":3,"user":{"displayName":"Hung-Ting Tsai","userId":"08907122957587206864"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["weights_int8 = np.fromfile('/content/drive/My Drive/Colab Notebooks/bin_files/conv1_weight.bin', dtype=np.int8)\n","\n","print(weights_int8.min(), weights_int8.max())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_m7dFeyo9Ngp","executionInfo":{"status":"ok","timestamp":1734579372864,"user_tz":-480,"elapsed":275,"user":{"displayName":"Hung-Ting Tsai","userId":"08907122957587206864"}},"outputId":"cb55175a-c2d7-499b-c947-8d7ed20c7e85"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["-128 112\n"]}]}]}