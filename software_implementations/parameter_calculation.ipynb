{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "ShsoQsgi2JuP",
        "oYhA9tF7BL3Z",
        "OGF-adSxBQ9b",
        "10rkhyO8B9DH",
        "cOkcA2k94nDz",
        "lupO5697dzkL",
        "Ps1lWEawd_bM",
        "n1djFvOteKFJ",
        "glwSkHNyeXyE",
        "i7ihhznbvDfb"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "The goal of this project is to train a ResNet-18 model on the CIFAR\n",
        "100 dataset, apply quantization-aware training (QAT), and deploy it on a\n",
        " Kria KV260 FPGA board.\n",
        "\n",
        " While ResNet-18 was initially trained on the\n",
        " ImageNet-1k dataset, for this assignment, you can either\n",
        " * (1) train it from scratchon CIFAR-100 (less recommended) or\n",
        " * (2) use ImageNet pre-trained weights to initialize the model for training on CIFAR-100"
      ],
      "metadata": {
        "id": "cJ9JmJ8R17x7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 1: Structure\n"
      ],
      "metadata": {
        "id": "ShsoQsgi2JuP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The architecture components are listed as follows:\n",
        "* Convolution(16, 3, 1, 1)\n",
        "* Batch Normalization (BN)\n",
        "* ReLU Activation\n",
        "* BasicBlock(16, 3, 1, 1) × 3\n",
        "* BasicBlock(32, 3, 2, 1)\n",
        "* BasicBlock(32, 3, 1, 1) × 2\n",
        "* BasicBlock(64, 3, 2, 1)\n",
        "* BasicBlock(64, 3, 1, 1) × 2\n",
        "* Average Pooling 2D (8, 1, 0)\n",
        "* Linear Layer (64, 10)\n"
      ],
      "metadata": {
        "id": "kh2GXko24i5M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup"
      ],
      "metadata": {
        "id": "oYhA9tF7BL3Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "from torch.utils.data import random_split\n",
        "from torch.utils.data import DataLoader\n",
        "import pandas as pd\n",
        "import time\n",
        "!pip install ptflops\n",
        "from ptflops import get_model_complexity_info"
      ],
      "metadata": {
        "id": "TZlOUfgH2y3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1316b6fa-801a-4f57-b88a-ae2d0ce8f2d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ptflops\n",
            "  Downloading ptflops-0.7.4-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: torch>=2.0 in /usr/local/lib/python3.10/dist-packages (from ptflops) (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->ptflops) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->ptflops) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->ptflops) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->ptflops) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->ptflops) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->ptflops) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=2.0->ptflops) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0->ptflops) (3.0.2)\n",
            "Downloading ptflops-0.7.4-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: ptflops\n",
            "Successfully installed ptflops-0.7.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Basic Block"
      ],
      "metadata": {
        "id": "OGF-adSxBQ9b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1  # No expansion in BasicBlock\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1, downsample=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.stride = stride\n",
        "\n",
        "        # First convolutional layer\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_channels, out_channels,\n",
        "            kernel_size=kernel_size, stride=stride, padding=padding, bias=False\n",
        "        )\n",
        "\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        # Second convolutional layer\n",
        "        self.conv2 = nn.Conv2d(\n",
        "            out_channels, out_channels,\n",
        "            kernel_size=kernel_size, stride=1, padding=padding, bias=False\n",
        "        )\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        # Downsample layer for shortcut connection (if needed)\n",
        "        self.downsample = downsample\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x  # Save the input tensor for the shortcut\n",
        "\n",
        "        # First layer\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        # Second layer\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        # Apply downsampling to the identity if necessary\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        # Add the identity (shortcut connection)\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "We_sAq1EBuDm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ResNet18"
      ],
      "metadata": {
        "id": "10rkhyO8B9DH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet18(nn.Module):\n",
        "    def __init__(self, num_classes=1000):\n",
        "        super(ResNet18, self).__init__()\n",
        "\n",
        "        # Initial Convolution and Max Pool\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "        # Define layers using your BasicBlock\n",
        "        self.layer1 = self._make_layer(64, 64, 2, stride=1)\n",
        "        self.layer2 = self._make_layer(64, 128, 2, stride=2)\n",
        "        self.layer3 = self._make_layer(128, 256, 2, stride=2)\n",
        "        self.layer4 = self._make_layer(256, 512, 2, stride=2)\n",
        "\n",
        "\n",
        "        # Adaptive Average Pooling\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "\n",
        "        # Fully connected layer\n",
        "        self.fc = nn.Linear(512 * BasicBlock.expansion, num_classes)\n",
        "\n",
        "        # Initialize weights\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def _make_layer(self, in_channels, out_channels, blocks, stride):\n",
        "        downsample = None\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(BasicBlock(in_channels, out_channels, stride=stride, downsample=downsample))\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(BasicBlock(out_channels, out_channels))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)"
      ],
      "metadata": {
        "id": "DqVNJS4pFaud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 2: Check Usage"
      ],
      "metadata": {
        "id": "cOkcA2k94nDz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate the number of trainable parameters, the minimum required onchip memory (in MB), the number of FLOPs (Floating Point Operations),\n",
        "and the model’s latency on both GPU and CPU."
      ],
      "metadata": {
        "id": "paGnJt2dGYQx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calculate the number of trainable parameters"
      ],
      "metadata": {
        "id": "lupO5697dzkL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def count_parameters(model):\n",
        "    # total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "    print(f\"Total Trainable Parameters: {total_params}\")\n",
        "    return total_params\n",
        "\n",
        "model = ResNet18()\n",
        "count_parameters(model)"
      ],
      "metadata": {
        "id": "Ric1vUryHCYR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28e52f48-ac65-4910-93e7-113e53aede4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Trainable Parameters: 11689512\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11689512"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calculate the minimum required onchip memory (in MB)"
      ],
      "metadata": {
        "id": "Ps1lWEawd_bM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model size in MB\n",
        "def get_model_size(model):\n",
        "    import torch\n",
        "    param_size = 0\n",
        "\n",
        "    for param in model.parameters():\n",
        "        param_size += param.nelement()  # param.element_size() after quantization will be 8-bit = 1 Byte\n",
        "    buffer_size = 0\n",
        "    for buffer in model.buffers():\n",
        "        buffer_size += buffer.nelement()  # buffer.element_size() after quantization will be 8-bit = 1 Byte\n",
        "    # model_size = (param_size + buffer_size) / 1024 ** 2  # Convert to MB\n",
        "    model_size = (param_size + buffer_size) / 1000 ** 2  # Convert to MB\n",
        "    print(f\"Model Size: {model_size:.2f} MB\")\n",
        "    return model_size\n",
        "\n",
        "model = ResNet18()\n",
        "get_model_size(model)"
      ],
      "metadata": {
        "id": "JA2tWZanHE2P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5d431f1-774d-4871-8f8a-1c5e07e86ceb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Size: 11.70 MB\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11.699132"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calculate the number of Multiply-Accumulate operations (MACs)"
      ],
      "metadata": {
        "id": "n1djFvOteKFJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_flops(model, input_res=32):\n",
        "    macs, params = get_model_complexity_info(\n",
        "        model, (3, input_res, input_res), as_strings=True,\n",
        "        print_per_layer_stat=False, verbose=False\n",
        "    )\n",
        "    print(f\"Computational Complexity (MACs): {macs}\")\n",
        "    print(f\"Number of Parameters: {params}\")\n",
        "\n",
        "model = ResNet18()\n",
        "compute_flops(model)"
      ],
      "metadata": {
        "id": "5SieHZGWHJwX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a335565a-b439-4a44-a219-0a98b6f3679c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computational Complexity (MACs): 37.75 MMac\n",
            "Number of Parameters: 11.69 M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calculate the model’s latency on both GPU and CPU"
      ],
      "metadata": {
        "id": "glwSkHNyeXyE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def measure_inference_time(model, device='cpu', input_size=(1, 3, 32, 32), num_runs=100):\n",
        "    model.eval()\n",
        "    model.to(device)   # IMPORTANT\n",
        "    input_tensor = torch.randn(input_size).to(device) # IMPORTANT\n",
        "\n",
        "    # Warm-up runs\n",
        "    with torch.no_grad():\n",
        "        for _ in range(10):\n",
        "            _ = model(input_tensor)\n",
        "\n",
        "    # Timing runs\n",
        "    timings = []\n",
        "    with torch.no_grad():\n",
        "        for _ in range(num_runs):\n",
        "            start_time = time.time()\n",
        "            _ = model(input_tensor)\n",
        "            end_time = time.time()\n",
        "            timings.append(end_time - start_time)\n",
        "\n",
        "    avg_time_per_run = sum(timings) / num_runs\n",
        "    throughput = input_size[0] / avg_time_per_run\n",
        "\n",
        "    print(f\"Average Inference Time: {avg_time_per_run * 1000:.2f} ms\")\n",
        "    print(f\"Throughput: {throughput:.2f} samples/sec\")\n",
        "\n",
        "model = ResNet18()\n",
        "print(f\"Latency on GPU\")\n",
        "measure_inference_time(model, device='cuda', input_size=(1, 3, 224, 224))\n",
        "print(f\"Latency on CPU\")\n",
        "measure_inference_time(model, device='cpu', input_size=(1, 3, 224, 224))"
      ],
      "metadata": {
        "id": "UpHVsnBlGlNW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c8368e2-1a06-4905-9163-bdec7ab62f7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Latency on GPU\n",
            "Average Inference Time: 3.21 ms\n",
            "Throughput: 311.79 samples/sec\n",
            "Latency on CPU\n",
            "Average Inference Time: 114.10 ms\n",
            "Throughput: 8.76 samples/sec\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BottleNeck Check for each components"
      ],
      "metadata": {
        "id": "i7ihhznbvDfb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.profiler import profile, record_function, ProfilerActivity\n",
        "\n",
        "model = model.eval()\n",
        "inputs = torch.randn(5, 3, 224, 224)\n",
        "\n",
        "with profile(activities=[ProfilerActivity.CPU], profile_memory=True, record_shapes=True) as prof:\n",
        "    with record_function(\"model_inference\"):\n",
        "        model(inputs)\n",
        "\n",
        "print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))\n",
        "print(type(model))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_sfuUpl2vK3j",
        "outputId": "ba1b87e3-2f46-43d2-ff6f-c2a2ecd6b336"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                             Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
            "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                  model_inference         2.11%       6.452ms       100.00%     306.329ms     306.329ms           0 b    -106.26 Mb             1  \n",
            "                     aten::conv2d         0.08%     245.608us        74.59%     228.503ms      11.425ms      47.37 Mb           0 b            20  \n",
            "                aten::convolution         0.12%     369.278us        74.51%     228.257ms      11.413ms      47.37 Mb           0 b            20  \n",
            "               aten::_convolution         0.08%     243.013us        74.39%     227.888ms      11.394ms      47.37 Mb           0 b            20  \n",
            "         aten::mkldnn_convolution        74.16%     227.168ms        74.31%     227.645ms      11.382ms      47.37 Mb           0 b            20  \n",
            "                 aten::max_pool2d         0.00%      13.814us        15.68%      48.041ms      48.041ms      11.48 Mb           0 b             1  \n",
            "    aten::max_pool2d_with_indices        15.68%      48.027ms        15.68%      48.027ms      48.027ms      11.48 Mb      11.48 Mb             1  \n",
            "                 aten::batch_norm         0.03%      86.281us         5.54%      16.971ms     848.539us      47.37 Mb           0 b            20  \n",
            "     aten::_batch_norm_impl_index         1.19%       3.650ms         5.51%      16.885ms     844.225us      47.37 Mb           0 b            20  \n",
            "          aten::native_batch_norm         4.23%      12.956ms         4.30%      13.176ms     658.821us      47.37 Mb     -37.50 Kb            20  \n",
            "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 306.329ms\n",
            "\n",
            "<class '__main__.ResNet18'>\n"
          ]
        }
      ]
    }
  ]
}