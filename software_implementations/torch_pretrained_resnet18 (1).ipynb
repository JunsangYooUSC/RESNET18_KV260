{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyM+bgY304nEjYJoO8S7WQzi"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5ac1UmfEr1qF","executionInfo":{"status":"ok","timestamp":1734357102747,"user_tz":-480,"elapsed":9582,"user":{"displayName":"Hung-Ting Tsai","userId":"08907122957587206864"}},"outputId":"280cf46a-319b-4fd2-a592-835ad2bad758"},"outputs":[{"output_type":"stream","name":"stdout","text":["GPU is available and being used.\n","Using device: cuda\n"]}],"source":["from torchvision.models import resnet18, ResNet18_Weights\n","import random\n","import copy\n","import matplotlib.pyplot as plt\n","import torch.nn as nn\n","import numpy as np\n","import torch\n","import torch.optim as optim\n","import torchvision\n","from torchvision.transforms import Resize\n","import torchvision.transforms as transforms\n","import torchvision.models as models\n","import torch.quantization\n","from torch.utils.data import random_split\n","from torch.utils.data import DataLoader\n","import pandas as pd\n","import time\n","\n","\n","# use GPU if available\n","if torch.cuda.is_available():\n","        device = torch.device(\"cuda\")\n","        print(\"GPU is available and being used.\")\n","else:\n","        device = torch.device(\"cpu\")\n","        print(\"GPU is not available, using CPU instead.\")\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using device: {device}\")"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Bc3CAMEMuoe7","executionInfo":{"status":"ok","timestamp":1734357128827,"user_tz":-480,"elapsed":23581,"user":{"displayName":"Hung-Ting Tsai","userId":"08907122957587206864"}},"outputId":"149ceb99-8cee-454b-d7ff-68380fc0a4d7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# Hyperparameters:\n","learning_rate = 0.001\n","momentum = 0.9\n","weight_decay = 1e-3\n","\n","num_epochs = 15\n","T_max = num_epochs\n","eta_min = 1e-5\n"],"metadata":{"id":"PnSQncVOsAAd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"PsaBgXAjtTiU"}},{"cell_type":"code","source":["# Define transformations for CIFAR-100 dataset\n","transform_train = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n","    transforms.RandomRotation(15),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])\n","\n","transform_test = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])\n","\n","# Download the CIFAR-100 training dataset\n","download_train_dataset = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform=transform_train)\n","download_test_dataset = torchvision.datasets.CIFAR100(root='./data', train=False, download=True, transform=transform_test)\n","\n","batch_size = 64\n","# Create DataLoader for training and validation datasets\n","train_loader = DataLoader(download_train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n","test_loader = DataLoader(download_test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AmjaGnntsY7B","executionInfo":{"status":"ok","timestamp":1734357160668,"user_tz":-480,"elapsed":12968,"user":{"displayName":"Hung-Ting Tsai","userId":"08907122957587206864"}},"outputId":"411d4e4a-3ac7-4b79-b2a3-af0dfb4e45b5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./data/cifar-100-python.tar.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 169M/169M [00:08<00:00, 20.9MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/cifar-100-python.tar.gz to ./data\n","Files already downloaded and verified\n"]}]},{"cell_type":"code","source":["pretrained_model = models.resnet18(pretrained=True)\n","num_ftrs = pretrained_model.fc.in_features\n","pretrained_model.fc = nn.Linear(num_ftrs, 100)\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(pretrained_model.parameters(), lr=learning_rate)\n","scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=T_max, eta_min=eta_min)\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","pretrained_model.to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PAry82eMtbt4","executionInfo":{"status":"ok","timestamp":1734357182554,"user_tz":-480,"elapsed":666,"user":{"displayName":"Hung-Ting Tsai","userId":"08907122957587206864"}},"outputId":"44bcbfc7-7d02-4948-8a6b-082580292196"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=512, out_features=100, bias=True)\n",")"]},"metadata":{},"execution_count":8}]},{"cell_type":"markdown","source":["### Functions"],"metadata":{"id":"1Byth5p26S-w"}},{"cell_type":"code","source":["def load_checkpoint(model, optimizer, path):\n","    checkpoint = torch.load(path, map_location=device)\n","    model.load_state_dict(checkpoint['model_state_dict'])\n","    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","    epoch = checkpoint['epoch']\n","    model.to(device)\n","\n","    for state in optimizer.state.values():\n","        for k, v in state.items():\n","            if isinstance(v, torch.Tensor):\n","                state[k] = v.to(device)\n","    return model, optimizer, epoch\n","\n","def save_checkpoint(model, optimizer, epoch, path):\n","    # Create the directory if it doesn't exist\n","    import os\n","    os.makedirs(os.path.dirname(path), exist_ok=True)\n","    torch.save({\n","        'epoch': epoch,\n","        'model_state_dict': model.state_dict(),\n","        'optimizer_state_dict': optimizer.state_dict(),\n","    }, path)\n","\n","def evaluate(model, data_loader, device):\n","    model.eval()  # Set model to evaluation mode\n","    correct = 0\n","    total = 0\n","\n","    with torch.no_grad():  # Disable gradient calculation during evaluation\n","        for images, labels in data_loader:\n","            images = images.to(device)\n","            labels = labels.to(device)\n","\n","            outputs = model(images)  # Get predictions\n","            _, predicted = torch.max(outputs.data, 1)  # Get predicted class labels\n","\n","            total += labels.size(0)  # Update total number of samples\n","            correct += (predicted == labels).sum().item()  # Update number of correct predictions\n","\n","    accuracy = 100 * correct / total  # Calculate accuracy\n","    return accuracy"],"metadata":{"id":"yGOgRsoOu7Uv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Load from last check point"],"metadata":{"id":"-kdsl8P76s8u"}},{"cell_type":"code","source":["# Example usage before resuming training\n","checkpoint_path = '/content/drive/My Drive/Colab Notebooks/checkpoints/pretrain_resnet18.pth'\n","pretrained_model = ResNet18(num_classes=100)\n","\n","optimizer = torch.optim.Adam(pretrained_model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n","\n","pretrained_model, optimizer, start_epoch = load_checkpoint(pretrained_model, optimizer, checkpoint_path)\n","pretrained_model.to(device)\n","\n","# Define loss function and optimizer\n","criterion = nn.CrossEntropyLoss()\n","\n","# Create model, schedueler\n","scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=T_max, eta_min=eta_min)\n","\n","\n","# Verify the model\n","print(\"start epoch: \", start_epoch)\n","for name, param in pretrained_model.named_parameters():\n","    if param.requires_grad:\n","        print(name, param.data.shape, param.data.sum())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"si0D0huP6wTO","executionInfo":{"status":"ok","timestamp":1734365012416,"user_tz":-480,"elapsed":1311,"user":{"displayName":"Hung-Ting Tsai","userId":"08907122957587206864"}},"outputId":"e6d1a0ef-b24c-4577-a6db-bc4e4d23fe56"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-12-2f6ac4e18b27>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  checkpoint = torch.load(path, map_location=device)\n"]},{"output_type":"stream","name":"stdout","text":["start epoch:  14\n","conv1.weight torch.Size([64, 3, 7, 7]) tensor(-0.0831, device='cuda:0')\n","bn1.weight torch.Size([64]) tensor(15.1651, device='cuda:0')\n","bn1.bias torch.Size([64]) tensor(10.5746, device='cuda:0')\n","layer1.0.conv1.weight torch.Size([64, 64, 3, 3]) tensor(-252.3925, device='cuda:0')\n","layer1.0.bn1.weight torch.Size([64]) tensor(20.1336, device='cuda:0')\n","layer1.0.bn1.bias torch.Size([64]) tensor(-1.2524, device='cuda:0')\n","layer1.0.conv2.weight torch.Size([64, 64, 3, 3]) tensor(-79.8547, device='cuda:0')\n","layer1.0.bn2.weight torch.Size([64]) tensor(18.7809, device='cuda:0')\n","layer1.0.bn2.bias torch.Size([64]) tensor(-1.7764, device='cuda:0')\n","layer1.1.conv1.weight torch.Size([64, 64, 3, 3]) tensor(-170.1751, device='cuda:0')\n","layer1.1.bn1.weight torch.Size([64]) tensor(19.5954, device='cuda:0')\n","layer1.1.bn1.bias torch.Size([64]) tensor(-5.7394, device='cuda:0')\n","layer1.1.conv2.weight torch.Size([64, 64, 3, 3]) tensor(-129.5225, device='cuda:0')\n","layer1.1.bn2.weight torch.Size([64]) tensor(24.7789, device='cuda:0')\n","layer1.1.bn2.bias torch.Size([64]) tensor(-3.5377, device='cuda:0')\n","layer2.0.conv1.weight torch.Size([128, 64, 3, 3]) tensor(-375.3674, device='cuda:0')\n","layer2.0.bn1.weight torch.Size([128]) tensor(36.0362, device='cuda:0')\n","layer2.0.bn1.bias torch.Size([128]) tensor(-16.7661, device='cuda:0')\n","layer2.0.conv2.weight torch.Size([128, 128, 3, 3]) tensor(-586.1251, device='cuda:0')\n","layer2.0.bn2.weight torch.Size([128]) tensor(39.7254, device='cuda:0')\n","layer2.0.bn2.bias torch.Size([128]) tensor(-3.9100, device='cuda:0')\n","layer2.0.downsample.0.weight torch.Size([128, 64, 1, 1]) tensor(-56.4978, device='cuda:0')\n","layer2.0.downsample.1.weight torch.Size([128]) tensor(22.5557, device='cuda:0')\n","layer2.0.downsample.1.bias torch.Size([128]) tensor(-3.9100, device='cuda:0')\n","layer2.1.conv1.weight torch.Size([128, 128, 3, 3]) tensor(-623.6708, device='cuda:0')\n","layer2.1.bn1.weight torch.Size([128]) tensor(38.3533, device='cuda:0')\n","layer2.1.bn1.bias torch.Size([128]) tensor(-33.6367, device='cuda:0')\n","layer2.1.conv2.weight torch.Size([128, 128, 3, 3]) tensor(-791.1605, device='cuda:0')\n","layer2.1.bn2.weight torch.Size([128]) tensor(33.9417, device='cuda:0')\n","layer2.1.bn2.bias torch.Size([128]) tensor(-25.0653, device='cuda:0')\n","layer3.0.conv1.weight torch.Size([256, 128, 3, 3]) tensor(-1289.0010, device='cuda:0')\n","layer3.0.bn1.weight torch.Size([256]) tensor(75.5351, device='cuda:0')\n","layer3.0.bn1.bias torch.Size([256]) tensor(-42.3964, device='cuda:0')\n","layer3.0.conv2.weight torch.Size([256, 256, 3, 3]) tensor(-1717.4915, device='cuda:0')\n","layer3.0.bn2.weight torch.Size([256]) tensor(81.6151, device='cuda:0')\n","layer3.0.bn2.bias torch.Size([256]) tensor(-17.7448, device='cuda:0')\n","layer3.0.downsample.0.weight torch.Size([256, 128, 1, 1]) tensor(-170.4871, device='cuda:0')\n","layer3.0.downsample.1.weight torch.Size([256]) tensor(23.9458, device='cuda:0')\n","layer3.0.downsample.1.bias torch.Size([256]) tensor(-17.7448, device='cuda:0')\n","layer3.1.conv1.weight torch.Size([256, 256, 3, 3]) tensor(-3014.5835, device='cuda:0')\n","layer3.1.bn1.weight torch.Size([256]) tensor(66.0899, device='cuda:0')\n","layer3.1.bn1.bias torch.Size([256]) tensor(-73.1897, device='cuda:0')\n","layer3.1.conv2.weight torch.Size([256, 256, 3, 3]) tensor(-3478.6147, device='cuda:0')\n","layer3.1.bn2.weight torch.Size([256]) tensor(55.1559, device='cuda:0')\n","layer3.1.bn2.bias torch.Size([256]) tensor(-52.8234, device='cuda:0')\n","layer4.0.conv1.weight torch.Size([512, 256, 3, 3]) tensor(-5476.9194, device='cuda:0')\n","layer4.0.bn1.weight torch.Size([512]) tensor(127.7537, device='cuda:0')\n","layer4.0.bn1.bias torch.Size([512]) tensor(-138.2961, device='cuda:0')\n","layer4.0.conv2.weight torch.Size([512, 512, 3, 3]) tensor(-11898.0508, device='cuda:0')\n","layer4.0.bn2.weight torch.Size([512]) tensor(206.8254, device='cuda:0')\n","layer4.0.bn2.bias torch.Size([512]) tensor(-130.9835, device='cuda:0')\n","layer4.0.downsample.0.weight torch.Size([512, 256, 1, 1]) tensor(-595.4565, device='cuda:0')\n","layer4.0.downsample.1.weight torch.Size([512]) tensor(119.0379, device='cuda:0')\n","layer4.0.downsample.1.bias torch.Size([512]) tensor(-130.9835, device='cuda:0')\n","layer4.1.conv1.weight torch.Size([512, 512, 3, 3]) tensor(-20918.8828, device='cuda:0')\n","layer4.1.bn1.weight torch.Size([512]) tensor(142.3601, device='cuda:0')\n","layer4.1.bn1.bias torch.Size([512]) tensor(-143.3806, device='cuda:0')\n","layer4.1.conv2.weight torch.Size([512, 512, 3, 3]) tensor(-3570.6172, device='cuda:0')\n","layer4.1.bn2.weight torch.Size([512]) tensor(1055.0254, device='cuda:0')\n","layer4.1.bn2.bias torch.Size([512]) tensor(141.3846, device='cuda:0')\n","fc.weight torch.Size([100, 512]) tensor(-947.0810, device='cuda:0')\n","fc.bias torch.Size([100]) tensor(-0.1404, device='cuda:0')\n"]}]},{"cell_type":"markdown","source":["### Train"],"metadata":{"id":"YoLYxA0_6VQo"}},{"cell_type":"code","source":["# Initializing parameters with zeroes\n","total_train = torch.zeros(num_epochs)\n","correct_train = torch.zeros(num_epochs)\n","avg_loss_train = torch.zeros(num_epochs)\n","accuracy_train = torch.zeros(num_epochs)\n","\n","# TRAINING LOOP\n","print(\"START TRAINING........\")\n","train_losses = [] # store training loss for each batch\n","train_accuracies = [] # store training accuracy for each batch\n","test_accuracies = [] #store test accuracy after each epoch\n","\n","for epoch in range(start_epoch, num_epochs):\n","  pretrained_model.train() # Set the model to training mode\n","  batch_losses = []\n","  batch_accuracies = []\n","\n","  for input, target in train_loader:\n","      input, target = input.to(device), target.to(device)\n","\n","      # forward\n","      output = pretrained_model(input)\n","      loss = criterion(output, target)\n","\n","      # backward\n","      optimizer.zero_grad()\n","      loss.backward()\n","      optimizer.step()\n","\n","      # *** Add gradient clipping here ***\n","      torch.nn.utils.clip_grad_norm_(pretrained_model.parameters(), max_norm=1)\n","\n","\n","      # save data\n","      batch_losses.append(loss.item())\n","      _, predicted = output.max(1)\n","      total = target.size(0)\n","      correct = predicted.eq(target).sum().item()\n","      batch_accuracies.append(100. * correct / total)\n","\n","  train_losses.append(batch_losses) # append the batch losses for this epoch to the main list\n","  train_accuracies.append(batch_accuracies) # append the batch accuracies for this epoch to the main list\n","  avg_loss_train[epoch] = np.mean(batch_losses) # calculate and store average loss for the epoch\n","  accuracy_train[epoch] = np.mean(batch_accuracies) # calculate and store average accuracy for the epoch\n","\n","  #Validation after each epoch\n","  test_accuracy = evaluate(pretrained_model, test_loader, device)\n","  test_accuracies.append(test_accuracy)\n","\n","  checkpoint_path = '/content/drive/My Drive/Colab Notebooks/checkpoints/pretrain_resnet18.pth'\n","  if (epoch + 1) % 2 == 1:\n","        save_checkpoint(pretrained_model, optimizer, epoch, checkpoint_path)\n","  print(f\"Epoch [{epoch+1}/{num_epochs}] - \"\n","        f\"Train Loss: {avg_loss_train[epoch]:.4f} - \"\n","        f\"Train Accuracy: {accuracy_train[epoch]:.2f}% - \"\n","        f\"Validation Accuracy: {test_accuracy:.2f}% \"\n","        )\n","\n","  scheduler.step()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LHOOJ-7Lt_X6","executionInfo":{"status":"ok","timestamp":1734364975942,"user_tz":-480,"elapsed":4496240,"user":{"displayName":"Hung-Ting Tsai","userId":"08907122957587206864"}},"outputId":"e1485c3b-7ef2-4e0c-bef2-97a2d813c291"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["START TRAINING........\n","Epoch [5/15] - Train Loss: 0.4490 - Train Accuracy: 86.17% - Validation Accuracy: 75.79% \n","Epoch [6/15] - Train Loss: 0.3755 - Train Accuracy: 88.55% - Validation Accuracy: 76.11% \n","Epoch [7/15] - Train Loss: 0.3064 - Train Accuracy: 90.49% - Validation Accuracy: 76.17% \n","Epoch [8/15] - Train Loss: 0.2510 - Train Accuracy: 92.37% - Validation Accuracy: 77.21% \n","Epoch [9/15] - Train Loss: 0.1936 - Train Accuracy: 94.18% - Validation Accuracy: 76.82% \n","Epoch [10/15] - Train Loss: 0.1532 - Train Accuracy: 95.52% - Validation Accuracy: 77.17% \n","Epoch [11/15] - Train Loss: 0.1198 - Train Accuracy: 96.73% - Validation Accuracy: 77.48% \n","Epoch [12/15] - Train Loss: 0.0929 - Train Accuracy: 97.57% - Validation Accuracy: 77.91% \n","Epoch [13/15] - Train Loss: 0.0733 - Train Accuracy: 98.17% - Validation Accuracy: 78.18% \n","Epoch [14/15] - Train Loss: 0.0570 - Train Accuracy: 98.65% - Validation Accuracy: 78.32% \n","Epoch [15/15] - Train Loss: 0.0508 - Train Accuracy: 98.91% - Validation Accuracy: 78.22% \n"]}]}]}